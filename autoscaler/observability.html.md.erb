---
title: Using Debug Logging with App Autoscaler
owner: Autoscaler
---

This topic describes how to monitor App Autoscaler and its supporting VMware Tanzu Application Service for VMs (TAS for VMs) components through debug logging.


## <a id='overview'></a> Overview of



## <a id='allow-debug'></a> Configure Debug Logging for Autoscaler

[Does the **Do not forward debug logs** checkbox need to be configured at all before you can configure debug logging for Autoscaler?]

To configure debug logging for Autoscaler:

1. In a terminal window, run:

    ```
    cf target -o system -s autoscaling
    ```

1. Set the logging level for Autoscaler to `debug` by running:

    ```
    cf set-env autoscale LOG_LEVEL debug
    ```

1. Restart Autoscaler by running:

    ```
    cf restart autoscale
    ```
    <p class='note'><strong>Note:</strong> Re-starting Autoscaler briefly interrupts any processes it is currently performing.</p>

[What about procedures for viewing debug logs and scaling events?]

## <a id='observability'></a> Reviewing Autoscaler Usage

As an operator, you can use debug logs to see whether developers of your apps are using Autoscaler to scale their apps, as well as [what are the running app instance metrics and Cloud Controller API endpoint info below supposed to tell you?]

If you have configured debug logging for Autoscaler, Autoscaler logs the following metrics [How do you view debug logs? Where in the logs do these metrics appear?]:

* `autoscale.scale_up`: the number of times Autoscaler has scaled up an app
* `autoscale.scale_down`: the number of times Autoscaler has scaled down an app
* `autoscale.enabled_bindings`: the number of Autoscaler service bindings in [the entire TAS for VMs deployment? A particular space and/or org?]

<p class='note'><strong>Note:</strong> These metrics appear as log lines and are not currently emitted to Loggregator.</p>

You can also review the overall number of running app instances that Diego reports [and find out what, exactly?]. For more information, see [Running App Instances, Rate of Change](../../operating/monitoring/kpi.html#1hraverageofbbs.LRPsRunning) in _Key Performance Indicators_.

Because each team of developers may use different autoscaling rules for their apps, it may be difficult to make generalizations [about what?]. However, you can also overlay [compare?] the number of running app instances with other scaling metrics that the developers of your apps may be using. For more information about the , see [Router Handling Latency](../../operating/monitoring/kpi.html#latency) in _Key Performance Indicators_.

You can also query the `/v3/service_instances` endpoint of the Cloud Foundry API (CAPI), filtering by service plans that are associated with Autoscaler [how do you do this?]. [What sort of information does this provide?] For more information, see the [CAPI documentation](https://v3-apidocs.cloudfoundry.org/version/3.117.0/index.html#list-service-instances).


## <a id='failure-modes'></a> Failure Modes

Instead of always maintaining enough app instances to handle the maximum amount of traffic that you expect for your apps, Autoscaler allows you to provision only the number of app instances that are necessary based on metrics and your defined autoscaling rules. However, if Autoscaler or the TAS for VMs components that support Autoscaler fail, the app cannot scale up from a low level to meet the demands of your app usage.

If you are not using Autoscaler, TAS for VMs component failures might only impact the control plane [what does "control plane" mean in this context?] of your TAS for VMs deployment. Using Autoscaler adds a harder dependency on these components being available. [Does "adding a harder dependency" mean it's more important that these components remain available, or that increased demand makes it less likely that they'll be available?]

This section describes various ways in which the TAS for VMs components that support Autoscaler can fail. This is a non-exhaustive list. [Are the ones listed here the most common ones?] For each we list:

* Relevant Autoscaler debug log metrics
* Example messages that appear in the output of `cf autoscaling-events`
* Example errors in the Autoscaler debug log output

### <a id='log-cache'></a> Log Cache

Autoscaler depends heavily on Log Cache, which provides the majority of metrics that Autoscaler uses to determine when to scale an app. If Log Cache fails or
is insufficiently scaled, Autoscaler cannot retrieve metrics, so it cannot determine when to scale an app.

For more information about Log Cache, see [Logging and Metrics Architecture](../../loggregator/architecture.html) and [Log
Components](../../loggregator/agent-architecture.html#log-egress) in _Log and Metric Agent Architecture (Beta)_.

#### <a id='lc-debug-log-metrics'></a> Debug Log Metrics

Autoscaler logs the following metrics:

* `autoscale.logcache.read_errors`: errors that Autoscaler encounters when reading from Log Cache
* `autoscale.logcache_metric_fetch_duration`: the time Autoscaler takes to retrieve metrics from Log Cache

<p class='note'><strong>Note:</strong> These metrics appear as log lines and are not currently emitted to Loggregator.</p>

#### <a id='lc-gateway-unavailable'></a> Log Cache Gateway is Unavailable

When the Log Cache gateway is unavailable [as in it's not there, or Autoscaler simply fails to connect to it?], you see a scaling event similar to the following example:

```
Autoscaler did not receive any metrics for memory during the scaling window. Scaling down will be deferred until these metrics are available.
```

You also see app logs similar to the following example:

```
[APP/PROC/WEB/2] OUT logcache walker: unexpected status code 502
```

#### <a id='lc-node-failure'></a> Individual Log Cache Node Fails

Log Cache holds the log and metric envelopes for an app on a single Log Cache node. ["Node" = just a VM? Or physical server, worker machine, and/or VM?] When that Log Cache node fails, Autoscaler cannot retrieve those envelopes, so it cannot determine when to scale an app.

When the Log Cache node that holds the envelopes for an app fails, you see a scaling event similar to the following example:

```
Autoscaler did not receive any metrics for memory during the scaling window. Scaling down will be deferred until these metrics are available.
```

You also see app logs similar to the following example:

```
[APP/PROC/WEB/1] OUT logcache walker: unexpected status code 503
```

#### <a id='lc-node-unresponsive'></a> Log Cache Nodes are Unresponsive

When Log Cache nodes do not respond to requests from Autoscaler, you see a scaling event similar to the following example:

```
Autoscaler did not receive any metrics for memory during the scaling window. Scaling down will be deferred until these metrics are available.
```

You also see app logs similar to the following example:

```
[APP/PROC/WEB/2] OUT logcache walker: Get "https://log-cache.sys.example.com/api/v1/read/85a6aff3-c739-4364-8df3-44f1aa50662b": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
```

### <a id='cloud-controller'></a> Cloud Controller

Autoscaler reads the app metadata that the Cloud Controller stores to determine how many instances an app currently has. When Autoscaler scales the number of
app instances up or down, it sends a request to the Cloud Controller. Then, the Cloud Controller directs the Diego Cell that runs the app to stage the number
of app instances that Autoscaler has requested.

Autoscaler also uses the Cloud Controller to retrieve information about service bindings for RabbitMQ queues. [Service bindings *to* RabbitMQ queues, or service binding information to put *into* RabbitMQ queues? Research how RabbitMQ queues work.]

The Cloud Controller also authorizes Log Cache to provide log and metric envelopes to Autoscaler.

For more information about the Cloud Controller, see [Cloud Controller](../../concepts/architecture/cloud-controller.html).

#### <a id='cc-debug-log-metrics'></a> Debug Log Metrics

Autoscaler logs the following metrics:

* `autoscale.cloud_controller.calls`: The number of requests that have been made to the Cloud Controller [just by Autoscaler and Log Cache, or other components, as well?]
* `autoscale.cloud_controller.request_errors`: The number of requests to the Cloud Controller that resulted in an error [just by Autoscaler and Log Cache, or other components, as well?]
* `autoscale.cloud_controller.scale_errors`: The number of requests to scale an app that have resulted in an error

<p class='note'><strong>Note:</strong> These metrics appear as log lines and are not currently emitted to Loggregator.</p>

#### <a id='cc-api-stopped'></a> Cloud Controller API is Stopped

When the Cloud Controller API is stopped, you see a scaling event similar to the following example:

```
Unable to scale due to Cloud Controller error.
```

This is a generic error that may indicate that an app has reached one or more of its resource quota limits. [Is this an alternate explanation for the error appearing, or does the Cloud Controller API stopping cause an app to reach a resource quota limit?]

You also see app logs similar to the following example:

```
[APP/PROC/WEB/0] OUT level=error msg="[Cloud Controller - app summary] CloudController - route not found"`
```

#### <a id='cc-unresponsive'></a> Cloud Controller is Unresponsive

When the Cloud Controller does not respond to requests from Autoscaler or Log Cache, you see a scaling event similar to the following example:

```
Unable to scale due to Cloud Controller error.
```

This is a generic error that may indicate that an app has reached one or more of its resource quota limits. [Is this an alternate explanation for the error appearing, or does CC being unresponsive cause an app to reach a resource quota limit?]

You also see app logs similar to the following example:

```
[APP/PROC/WEB/0] OUT level=error msg="[Cloud Controller - app summary] failure connecting to cloud controller. Error: Get \"https://api.sys.example.com/v2/apps/85a6aff3-c739-4364-8df3-44f1aa50662b/summary\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)"
[APP/PROC/WEB/1] OUT level=error msg="[Cloud Controller - app summary] CloudController - Failure"
```

### <a id='mysql'></a> MySQL

Autoscaler stores persistent information about Autoscaler service bindings and the autoscaling rules you configure in a MySQL database.

If Autoscaler fails to select from or update the MySQL database, Autoscaler cannot scale your apps.

[Are there any debug log metrics for this?]

#### <a id='mysql-db-connection'></a> Autoscaler Fails to Connect to a MySQL Database

[Is there any example `cf autoscaling-events` output for this?]

You also see app logs similar to the following example:

```
[APP/PROC/WEB/0] OUT level=error msg="Unable to find any enabled service bindings by instance id" error="driver: bad connection" instance_id=0
[APP/PROC/WEB/2] ERR [mysql] packets.go:37: unexpected EOF
```

### <a id='diego-cells'></a> Diego Cells

Because Autoscaler is an app that you deploy through TAS for VMs, it uses the same resources that all other apps in your TAS for VMs deployment use. If all of
the Diego Cells that host [is this the right word?] Autoscaler fail, Autoscaler cannot scale your apps.

[Are there any debug log metrics for this?]

[Is there any example `cf autoscaling-events` output for this?]

[Are there any example logs for this?]


## <a id='scaling-Autoscaler'></a> Scaling Autoscaler

By default, there are three instances of Autoscaler app `autoscale` that perform the autoscaling. [But wait -- the ~~Highlander~~ troubleshooting topic says there can be only one!] Each works independently to try to claim a set of apps that may need to be scaled and process them.

An Autoscaler instance considers apps in batches of 10 when making scaling decisions. The number of batches that each instance of Autoscaler can process is mostly governed by the number of metrics for those apps it retrieves from Log Cache. If Log Cache holds a large number of metrics for an app, Autoscaler does not proceed to the next batch until either it retrieves all of those metrics or the request times out.

To ensure that all apps configured for autoscaling are processed in a timely manner, you may need to increase the number of Autoscaler instances.

To increase the number of Autoscaler instances:

1. Navigate to the Ops Manager Installation Dashboard.

1. Click the **VMware Tanzu Application Service** tile.

1. Select **App Autoscaler**.

1. In the **Autoscaler instance count** field, enter the number of Autoscaler instances you want to deploy.

1. Click **Save**. [Do you need to re-deploy TAS for VMs at this point?]

1. Return to the Ops Manager Installation Dashboard.

1. Click **Review Pending Changes**.

1. Under the **VMware Tanzu Application Service** tile, click **Errands**. The **Errands** menu expands.

1. Ensure that the **App Autoscaler Errand** checkbox is activated.

1. Click **Apply Changes**.
